{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vk\n",
    "import time\n",
    "import math\n",
    "from pprint import pprint\n",
    "from collections import deque\n",
    "import tqdm\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "\n",
    "MAX_COUNT = 200\n",
    "FIELDS = 'first_name,last_name,screen_name,bdate,common_count,is_friend,photo_max,photo_50'\n",
    "API_VERSION = '5.87'\n",
    "\n",
    "flags = {'get_chats': True,\n",
    "        'min_len': None, \n",
    "        'test_run': True,\n",
    "        'creds_path':'creds.json'}\n",
    "\n",
    "\n",
    "logger =logging.getLogger(__name__)\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "def get_password_and_id(cp):\n",
    "    creds = json.load(open(cp))\n",
    "    return creds['pass'], creds['id']\n",
    "\n",
    "password, id = get_password_and_id(flags['creds_path'])\n",
    "\n",
    "session = vk.AuthSession(app_id='6787646', user_login=id,\n",
    "                         scope='messages', user_password=password) if password else vk.AuthSession()\n",
    "vkapi = vk.API(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Throater:\n",
    "    \n",
    "    def __init__(self, mrc = 3, ti = 1.5):\n",
    "        self.total_sleep = 0\n",
    "        self.time_interval = ti\n",
    "        self.max_req_c = mrc\n",
    "        self.history = deque([0]*self.max_req_c)\n",
    "    def ready(self):\n",
    "        now = time.time()\n",
    "        self.history.append(now)\n",
    "        prev = self.history.popleft()\n",
    "        to_sleep = prev + self.time_interval - now \n",
    "        if to_sleep > 0:\n",
    "            self.total_sleep += to_sleep\n",
    "            time.sleep(to_sleep)\n",
    "        return\n",
    "t = Throater()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list(func, initial_offset = 0, **kwargs):\n",
    "    begin_t = time.time()\n",
    "    i = 0\n",
    "    t.ready()\n",
    "    things = func(v='5.87', count = MAX_COUNT, offset = initial_offset, **kwargs)\n",
    "    count = things['count']\n",
    "    things = things['items']\n",
    "    while len(things)< count-initial_offset:\n",
    "        i+=1\n",
    "        t.ready()\n",
    "        new_things = func(v=API_VERSION, count = MAX_COUNT, offset = initial_offset + len(things), **kwargs)\n",
    "        things.extend(new_things['items'])\n",
    "    return things\n",
    "\n",
    "def get_all_messages(peer_id, initial_offset = 0):\n",
    "    return get_list(vkapi.messages.getHistory,initial_offset, user_id = peer_id)\n",
    "\n",
    "def get_all_convs(initial_offset=0):\n",
    "    return get_list(vkapi.messages.getConversations,initial_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dm_and_chat_ids_from_convs(convs):\n",
    "    direct_conv_ids = []\n",
    "    chat_conv_ids = []\n",
    "    for c in convs:\n",
    "        peer = c['conversation']['peer']\n",
    "\n",
    "        if peer['type'] == 'user':\n",
    "            direct_conv_ids.append(peer['id'])\n",
    "        else:\n",
    "            chat_conv_ids.append(peer['id'])\n",
    "    return direct_conv_ids, chat_conv_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_draft(ids):\n",
    "    data = {'total_msg_count':0, 'items':{}}\n",
    "    for i in tqdm.tqdm_notebook(ids):\n",
    "        t.ready()\n",
    "        batch = vkapi.messages.getHistory(v=API_VERSION, count = MAX_COUNT, extended = 1, fields=FIELDS, peer_id = i)\n",
    "        count = batch['count']\n",
    "        data['total_msg_count'] += count\n",
    "        data['items'][i] = batch\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_requests(data):\n",
    "    r = 0\n",
    "    l = 0\n",
    "    for v in list(data['items'].values()):\n",
    "        done = len(v['items'])\n",
    "        left = v['count'] - done\n",
    "        r += math.ceil(left/MAX_COUNT)\n",
    "        l += left\n",
    "    return r, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_data_draft(data):\n",
    "    ids = list(data['items'].keys())\n",
    "    \n",
    "    ids.sort(key = lambda x: data['items'][x]['count'])\n",
    "    rn, l = estimate_requests(data)\n",
    "    logger.info('Need to download {} messages in {} requests'.format(l, rn))\n",
    "    with tqdm.tqdm_notebook(total = rn) as pbar:\n",
    "        for user_id in ids:\n",
    "            done = len(data['items'][user_id]['items'])\n",
    "            total = data['items'][user_id]['count']\n",
    "            if done >= total:\n",
    "                continue\n",
    "            expected_requests = math.ceil((total - done)/MAX_COUNT)\n",
    "            data['items'][user_id]['items'].extend(get_all_messages(user_id, done))\n",
    "            # here we might miss some info about attached messages authors. \n",
    "            pbar.update(expected_requests)\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_messages_data():\n",
    "    logger.info('Getting info about all conversations')\n",
    "    convs = get_all_convs()\n",
    "    dmi, ci = get_dm_and_chat_ids_from_convs(convs)\n",
    "    if not flags['get_chats']: ci = []\n",
    "    if flags['test_run']: dmi, ci = dmi[:5],ci[:5]\n",
    "    logger.info('Starting fetch \\n Collecting meta info and estimates')\n",
    "    data = get_data_draft(dmi+ci)\n",
    "    logger.info('Meta info collected. \\nTotal messages found: {}\\nCollecting messages text'.format(data['total_msg_count']))\n",
    "    data = complete_data_draft(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-18 20:10:26,401 | INFO : Starting fetch \n",
      " Collecting meta info and estimates\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a10a9dc73c4653bbe9683638f90885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-12-18 20:10:31,397 | INFO : Meta info collected. \n",
      "Total messages found: 64932\n",
      "Collecting messages text\n",
      "2018-12-18 20:10:31,398 | INFO : Need to download 63324 messages in 321 requests\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b2ffce757b45768dd73587c69ac686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=321), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = get_all_messages_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_conversations_from_draft(data):\n",
    "    ids = list(data['items'].keys())\n",
    "    \n",
    "    ids.sort(key = lambda x: data['items'][x]['count'])\n",
    "    rn, l = estimate_requests(data)\n",
    "    logger.info('Need to download {} messages in {} requests'.format(l, rn))\n",
    "    with tqdm.tqdm_notebook(total = rn) as pbar:\n",
    "        for user_id in ids:\n",
    "            obj = data['items'][user_id]\n",
    "            done = len(obj['items'])\n",
    "            total = obj['count']\n",
    "            if done >= total:\n",
    "                yield obj\n",
    "                continue\n",
    "            expected_requests = math.ceil((total - done)/MAX_COUNT)\n",
    "            \n",
    "            obj['items'].extend(get_all_messages(user_id, done))\n",
    "            # here we might miss some info about attached messages authors. \n",
    "            pbar.update(expected_requests)\n",
    "            yield obj\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_messages_data():\n",
    "    logger.info('Getting info about all conversations')\n",
    "    convs = get_all_convs()\n",
    "    dmi, ci = get_dm_and_chat_ids_from_convs(convs)\n",
    "    if not flags['get_chats']: ci = []\n",
    "    if flags['test_run']: dmi, ci = dmi[:5],ci[:5]\n",
    "    logger.info('Starting fetch \\n Collecting meta info and estimates')\n",
    "    data = get_data_draft(dmi+ci)\n",
    "    logger.info('Meta info collected. \\nTotal messages found: {}\\nCollecting messages text'.format(data['total_msg_count']))\n",
    "    data = complete_data_draft(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(data, open('nikkorobk_data_first_iteration.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pass': 'your_pass_here', 'id': 'your_id_here'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creds = json.load(open('creds.json'))\n",
    "creds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not flags['get_chats']: ci = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
